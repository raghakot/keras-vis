<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>visualization - Keras-vis Documentation</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../css/extras.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "visualization";
    var mkdocs_page_input_path = "vis.visualization.md";
    var mkdocs_page_url = "/vis.visualization/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Keras-vis Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Visualizations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../visualizations/conv_filters/">Convolutional Filters</a>
                </li>
                <li class="">
                    
    <a class="" href="../visualizations/dense/">Dense Layers</a>
                </li>
                <li class="">
                    
    <a class="" href="../visualizations/attention/">Attention Maps</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">API Docs</span>
    <ul class="subnav">
                <li class=" current">
                    
    <span class="caption-text">Core API</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../vis.losses/">losses</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../vis.regularizers/">regularizers</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../vis.modifiers/">modifiers</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../vis.optimizer/">optimizer</a>
                </li>
                <li class="toctree-l3 current">
                    
    <a class="current" href="./">visualization</a>
    <ul class="subnav">
            
    <li class="toctree-l4"><a href="#get_num_filters">get_num_filters</a></li>
    

    <li class="toctree-l4"><a href="#overlay">overlay</a></li>
    

    <li class="toctree-l4"><a href="#visualize_activation">visualize_activation</a></li>
    

    <li class="toctree-l4"><a href="#visualize_class_activation">visualize_class_activation</a></li>
    

    <li class="toctree-l4"><a href="#visualize_regression_activation">visualize_regression_activation</a></li>
    

    <li class="toctree-l4"><a href="#visualize_saliency">visualize_saliency</a></li>
    

    <li class="toctree-l4"><a href="#visualize_class_saliency">visualize_class_saliency</a></li>
    

    <li class="toctree-l4"><a href="#visualize_regression_saliency">visualize_regression_saliency</a></li>
    

    <li class="toctree-l4"><a href="#visualize_cam">visualize_cam</a></li>
    

    <li class="toctree-l4"><a href="#visualize_class_cam">visualize_class_cam</a></li>
    

    <li class="toctree-l4"><a href="#visualize_regression_cam">visualize_regression_cam</a></li>
    

    </ul>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <span class="caption-text">Utils</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../vis.utils.utils/">utils</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../vis.utils.vggnet/">vggnet</a>
                </li>
    </ul>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Keras-vis Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>API Docs &raquo;</li>
        
      
        
          <li>Core API &raquo;</li>
        
      
    
    <li>visualization</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/raghakot/keras-vis/blob/master/docs/templates/vis.visualization.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p><strong>Source:</strong> <a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L0">vis/visualization.py#L0</a></p>
<hr />
<h3 id="get_num_filters"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L55">get_num_filters</a></h3>
<pre><code class="python">get_num_filters(layer)
</code></pre>

<p>Determines the number of filters within the give <code>layer</code>.</p>
<p><em>Returns:</em></p>
<p>Total number of filters within <code>layer</code>.
  For <code>keras.layers.Dense</code> layer, this is the total number of outputs.</p>
<hr />
<h3 id="overlay"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L70">overlay</a></h3>
<pre><code class="python">overlay(array1, array2, alpha=0.5)
</code></pre>

<p>Overlays <code>array1</code> onto <code>array2</code> with <code>alpha</code> blending.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>array1</strong>:  The first numpy array.</li>
<li><strong>array2</strong>:  The second numpy array.</li>
<li><strong>alpha</strong>:  The alpha value of <code>array1</code> as overlayed onto <code>array2</code>. This value needs to be between [0, 1],
  with 0 being <code>array2</code> only to 1 being <code>array1</code> only (Default value = 0.5).</li>
</ul>
<p><em>Returns:</em></p>
<p>The <code>array1</code>, overlayed with <code>array2</code> using <code>alpha</code> blending.</p>
<hr />
<h3 id="visualize_activation"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L90">visualize_activation</a></h3>
<pre><code class="python">visualize_activation(input_tensor, losses, seed_input=None, input_range=(0, 255), \
    **optimizer_params)
</code></pre>

<p>Generates the <code>input_tensor</code> that minimizes the weighted <code>losses</code>.</p>
<p>This function is intended for advanced use cases where a custom loss is desired. For common use cases,
refer to <code>visualize_class_activation</code> or <code>visualize_regression_activation</code>.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>input_tensor</strong>:  An input tensor of shape: <code>(samples, channels, image_dims...)</code> if <code>image_data_format=
  channels_first</code> or <code>(samples, image_dims..., channels)</code> if <code>image_data_format=channels_last</code>.</li>
<li><strong>losses</strong>:  List of (<a href="../vis.losses#Loss">Loss</a>, weight) tuples.</li>
<li><strong>seed_input</strong>:  Seeds the optimization with a starting image. Initialized with a random value when set to None.
  (Default value = None)</li>
<li><strong>input_range</strong>:  Specifies the input range as a <code>(min, max)</code> tuple. This is used to rescale the
  final optimized input to the given range. (Default value=(0, 255))</li>
<li><strong>optimizer_params</strong>:  The **kwargs for optimizer <a href="../vis.optimizer/##optimizerminimize">params</a>. Will default to
  reasonable values when required keys are not found.</li>
</ul>
<p><em>Returns:</em></p>
<p>The model input that minimizes the weighted <code>losses</code>.</p>
<hr />
<h3 id="visualize_class_activation"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L132">visualize_class_activation</a></h3>
<pre><code class="python">visualize_class_activation(model, layer_idx, filter_indices=None, seed_input=None, input_range=(0, \
    255), act_max_weight=1, lp_norm_weight=10, tv_weight=10, **optimizer_params)
</code></pre>

<p>Generates the model input that maximizes the output of all <code>filter_indices</code> in the given <code>layer_idx</code>.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>model</strong>:  The <code>keras.models.Model</code> instance. The model input shape must be: <code>(samples, channels, image_dims...)</code>
  if <code>image_data_format=channels_first</code> or <code>(samples, image_dims..., channels)</code> if
  <code>image_data_format=channels_last</code>.</li>
<li><strong>layer_idx</strong>:  The layer index within <code>model.layers</code> whose filters needs to be visualized.</li>
<li><strong>filter_indices</strong>:  filter indices within the layer to be maximized.
  If None, all filters are visualized. (Default value = None)</li>
</ul>
<p>For <code>keras.layers.Dense</code> layer, <code>filter_idx</code> is interpreted as the output index.</p>
<p>If you are visualizing final <code>keras.layers.Dense</code> layer, you tend to get
  better results with 'linear' activation as opposed to 'softmax'. This is because 'softmax'
  output can be maximized by minimizing scores for other classes.</p>
<ul>
<li><strong>seed_input</strong>:  Seeds the optimization with a starting input. Initialized with a random value when set to None.
  (Default value = None)</li>
<li><strong>input_range</strong>:  Specifies the input range as a <code>(min, max)</code> tuple. This is used to rescale the
  final optimized input to the given range. (Default value=(0, 255))</li>
<li><strong>act_max_weight</strong>:  The weight param for <code>ActivationMaximization</code> loss. Not used if 0 or None. (Default value = 1)</li>
<li><strong>lp_norm_weight</strong>:  The weight param for <code>LPNorm</code> regularization loss. Not used if 0 or None. (Default value = 10)</li>
<li><strong>tv_weight</strong>:  The weight param for <code>TotalVariation</code> regularization loss. Not used if 0 or None. (Default value = 10)</li>
<li><strong>optimizer_params</strong>:  The **kwargs for optimizer <a href="../vis.optimizer/##optimizerminimize">params</a>. Will default to
  reasonable values when required keys are not found.</li>
</ul>
<p><em>Example:</em></p>
<p>If you wanted to visualize the input image that would maximize the output index 22, say on
final <code>keras.layers.Dense</code> layer, then, <code>filter_indices = [22]</code>, <code>layer_idx = dense_layer_idx</code>.</p>
<p>If <code>filter_indices = [22, 23]</code>, then it should generate an input image that shows features of both classes.</p>
<p><em>Returns:</em></p>
<p>The model input that maximizes the output of <code>filter_indices</code> in the given <code>layer_idx</code>.</p>
<hr />
<h3 id="visualize_regression_activation"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L179">visualize_regression_activation</a></h3>
<pre><code class="python">visualize_regression_activation(model, layer_idx, output_indices, targets, seed_img=None, \
    input_range=(0, 255), reg_target_weight=1.0, lp_norm_weight=0.001, tv_weight=0.001, \
    **optimizer_params)
</code></pre>

<p>Generates a model input that drives the outputs of <code>output_indices</code> in the given <code>layer_idx</code> to the
corresponding regression <code>targets</code>.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>model</strong>:  The <code>keras.models.Model</code> instance. The model input shape must be: <code>(samples, channels, image_dims...)</code>
  if <code>image_data_format=channels_first</code> or <code>(samples, image_dims..., channels)</code> if
  <code>image_data_format=channels_last</code>.</li>
<li><strong>layer_idx</strong>:  The layer index within <code>model.layers</code> whose output indices needs to be considered.</li>
<li><strong>output_indices</strong>:  Output indices within the layer for the corresponding regression <code>targets</code>.</li>
<li><strong>targets</strong>:  The regression targets for the corresponding <code>output_indices</code>.</li>
<li><strong>seed_img</strong>:  Seeds the optimization with a starting image. Initialized with a random value when set to None.
  (Default value = None)</li>
<li><strong>input_range</strong>:  Specifies the input range as a <code>(min, max)</code> tuple. This is used to rescale the
  final optimized input to the given range. (Default value=(0, 255))</li>
<li><strong>reg_target_weight</strong>:  The weight param for <code>RegressionTarget</code> loss. Not used if 0 or None.
  (Default value = 1)</li>
<li><strong>lp_norm_weight</strong>:  The weight param for <code>LPNorm</code> regularization loss. Not used if 0 or None.
  (Default value = 1e-3)</li>
<li><strong>tv_weight</strong>:  The weight param for <code>TotalVariation</code> regularization loss. Not used if 0 or None.
  (Default value = 1e-3)</li>
<li><strong>optimizer_params</strong>:  The **kwargs for optimizer <a href="../vis.optimizer/##optimizerminimize">params</a>. Will default to
  reasonable values when required keys are not found.</li>
</ul>
<p><em>Example:</em></p>
<p>Consider a model with continuous regression output such as the self driving car.</p>
<p>If you wanted to visualize the input image that would cause the final <code>Dense</code> layer output_index 0 to output
45 degrees, then you would set <code>output_indices = 0</code>, <code>layer_idx = dense_layer_idx</code> and <code>targets = 45</code></p>
<p>Suppose this model has two regression outputs, one for the steering angle and another for acceleration.
Setting <code>output_indices = [0, 1]</code>, <code>layer_idx = dense_layer_idx</code> and <code>targets = [45, -5]</code> would generate
the model input that would cause the steering angle to increase but the acceleration to decrease.</p>
<p><em>Returns:</em></p>
<p>The model input that causes regression <code>output_indices</code> outputs to approach their corresponding <code>targets</code>.</p>
<hr />
<h3 id="visualize_saliency"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L227">visualize_saliency</a></h3>
<pre><code class="python">visualize_saliency(input_tensor, losses, seed_input)
</code></pre>

<p>Generates an attention heatmap over the <code>seed_input</code> by using positive gradients of <code>input_tensor</code>
with respect to weighted <code>losses</code>.</p>
<p>This function is intended for advanced use cases where a custom loss is desired. For common use cases,
refer to <code>visualize_class_saliency</code> or <code>visualize_regression_saliency</code>.</p>
<p>For a full description of saliency, see the paper:
<a href="https://arxiv.org/pdf/1312.6034v2.pdf">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a></p>
<p><em>Args:</em></p>
<ul>
<li><strong>input_tensor</strong>:  An input tensor of shape: <code>(samples, channels, image_dims...)</code> if <code>image_data_format=
  channels_first</code> or <code>(samples, image_dims..., channels)</code> if <code>image_data_format=channels_last</code>.</li>
<li><strong>losses</strong>:  List of (<a href="../vis.losses#Loss">Loss</a>, weight) tuples.</li>
<li><strong>seed_input</strong>:  The model input for which activation map needs to be visualized.</li>
</ul>
<p><em>Returns:</em></p>
<p>The heatmap image indicating the <code>seed_input</code> regions whose change would most contribute towards minimizing
weighted <code>losses</code>.</p>
<hr />
<h3 id="visualize_class_saliency"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L258">visualize_class_saliency</a></h3>
<pre><code class="python">visualize_class_saliency(model, layer_idx, filter_indices, seed_input)
</code></pre>

<p>Generates an attention heatmap over the <code>seed_input</code> for maximizing <code>filter_indices</code>
output in the given <code>layer_idx</code>.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>model</strong>:  The <code>keras.models.Model</code> instance. The model input shape must be: <code>(samples, channels, image_dims...)</code>
  if <code>image_data_format=channels_first</code> or <code>(samples, image_dims..., channels)</code> if
  <code>image_data_format=channels_last</code>.</li>
<li><strong>layer_idx</strong>:  The layer index within <code>model.layers</code> whose filters needs to be visualized.</li>
<li><strong>filter_indices</strong>:  filter indices within the layer to be maximized.
  For <code>keras.layers.Dense</code> layer, <code>filter_idx</code> is interpreted as the output index.</li>
</ul>
<p>If you are visualizing final <code>keras.layers.Dense</code> layer, you tend to get
  better results with 'linear' activation as opposed to 'softmax'. This is because 'softmax'
  output can be maximized by minimizing scores for other classes.</p>
<ul>
<li><strong>seed_input</strong>:  The model input for which activation map needs to be visualized.</li>
</ul>
<p><em>Example:</em></p>
<p>If you wanted to visualize attention over 'bird' category, say output index 22 on the
final <code>keras.layers.Dense</code> layer, then, <code>filter_indices = [22]</code>, <code>layer = dense_layer</code>.</p>
<p>One could also set filter indices to more than one value. For example, <code>filter_indices = [22, 23]</code> should
(hopefully) show attention map that corresponds to both 22, 23 output categories.</p>
<p><em>Returns:</em></p>
<p>The heatmap image indicating the <code>seed_input</code> regions whose change would most contribute towards
maximizing the output of <code>filter_indices</code>.</p>
<hr />
<h3 id="visualize_regression_saliency"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L295">visualize_regression_saliency</a></h3>
<pre><code class="python">visualize_regression_saliency(model, layer_idx, output_indices, targets, seed_input)
</code></pre>

<p>Generates an attention heatmap over the <code>seed_input</code> for driving the outputs of <code>output_indices</code>
in the given <code>layer_idx</code> to the corresponding regression <code>targets</code>.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>model</strong>:  The <code>keras.models.Model</code> instance. The model input shape must be: <code>(samples, channels, image_dims...)</code>
  if <code>image_data_format=channels_first</code> or <code>(samples, image_dims..., channels)</code> if
  <code>image_data_format=channels_last</code>.</li>
<li><strong>layer_idx</strong>:  The layer index within <code>model.layers</code> whose filters needs to be visualized.</li>
<li><strong>output_indices</strong>:  Output indices within the layer for the corresponding regression <code>targets</code>.</li>
<li><strong>targets</strong>:  The regression targets for the corresponding <code>output_indices</code>.</li>
<li><strong>seed_input</strong>:  The model input for which activation map needs to be visualized.</li>
</ul>
<p><em>Example:</em></p>
<p>Consider a model with continuous regression output such as the self driving car.</p>
<p>If you wanted to visualize the attention over input image that would cause the final <code>Dense</code> layer output_index
0 to output 45 degrees, then you would set <code>output_indices = 0</code>, <code>layer_idx = dense_layer_idx</code> and <code>targets = 45</code>.</p>
<p>Suppose this model has two regression outputs, one for the steering angle and another for acceleration.
Setting <code>output_indices = [0, 1]</code>, <code>layer_idx = dense_layer_idx</code> and <code>targets = [45, -5]</code> would generate
the attention heatmap over input that would cause the steering angle to increase and acceleration to decrease.</p>
<p><em>Returns:</em></p>
<p>The heatmap image indicating the <code>seed_input</code> regions whose change would most contribute towards <code>output_indices</code>
outputs to approach their corresponding <code>targets</code>.</p>
<hr />
<h3 id="visualize_cam"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L330">visualize_cam</a></h3>
<pre><code class="python">visualize_cam(input_tensor, losses, seed_input, penultimate_layer)
</code></pre>

<p>Generates a gradient based class activation map (CAM) by using positive gradients of <code>input_tensor</code>
with respect to weighted <code>losses</code>.</p>
<p>For details on grad-CAM, see the paper:
<a href="https://arxiv.org/pdf/1610.02391v1.pdf">Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization</a>.</p>
<p>Unlike <a href="https://arxiv.org/pdf/1512.04150v1.pdf">class activation mapping</a>, which requires minor changes to
network architecture in some instances, grad-CAM has a more general applicability.</p>
<p>Compared to saliency maps, grad-CAM is class discriminative; i.e., the 'cat' explanation exclusively highlights
cat regions and not the 'dog' region and vice-versa.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>input_tensor</strong>:  An input tensor of shape: <code>(samples, channels, image_dims...)</code> if <code>image_data_format=
  channels_first</code> or <code>(samples, image_dims..., channels)</code> if <code>image_data_format=channels_last</code>.</li>
<li><strong>losses</strong>:  List of (<a href="../vis.losses#Loss">Loss</a>, weight) tuples.</li>
<li><strong>seed_input</strong>:  The model input for which activation map needs to be visualized.</li>
<li><strong>penultimate_layer</strong>:  The pre-layer to <code>layer_idx</code> whose feature maps should be used to compute gradients
  with respect to filter output.</li>
</ul>
<p><em>Notes:</em></p>
<p>This technique deprecates occlusion maps as it gives similar results, but with one-pass gradient computation
as opposed inefficient sliding window approach.</p>
<p><em>Returns:</em></p>
<p>The heatmap image indicating the <code>seed_input</code> regions whose change would most contribute towards minimizing the
weighted <code>losses</code>.</p>
<hr />
<h3 id="visualize_class_cam"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L394">visualize_class_cam</a></h3>
<pre><code class="python">visualize_class_cam(model, layer_idx, filter_indices, seed_input, penultimate_layer_idx=None)
</code></pre>

<p>Generates a gradient based class activation map (grad-CAM) that maximizes the outputs of
<code>filter_indices</code> in <code>layer_idx</code>.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>model</strong>:  The <code>keras.models.Model</code> instance. The model input shape must be: <code>(samples, channels, image_dims...)</code>
  if <code>image_data_format=channels_first</code> or <code>(samples, image_dims..., channels)</code> if
  <code>image_data_format=channels_last</code>.</li>
<li><strong>layer_idx</strong>:  The layer index within <code>model.layers</code> whose filters needs to be visualized.</li>
<li><strong>filter_indices</strong>:  filter indices within the layer to be maximized.
  For <code>keras.layers.Dense</code> layer, <code>filter_idx</code> is interpreted as the output index.</li>
</ul>
<p>If you are visualizing final <code>keras.layers.Dense</code> layer, you tend to get
  better results with 'linear' activation as opposed to 'softmax'. This is because 'softmax'
  output can be maximized by minimizing scores for other classes.</p>
<ul>
<li><strong>seed_input</strong>:  The input image for which activation map needs to be visualized.</li>
<li><strong>penultimate_layer_idx</strong>:  The pre-layer to <code>layer_idx</code> whose feature maps should be used to compute gradients
  wrt filter output. If not provided, it is set to the nearest penultimate <code>Conv</code> or <code>Pooling</code> layer.</li>
</ul>
<p><em>Example:</em></p>
<p>If you wanted to visualize attention over 'bird' category, say output index 22 on the
final <code>keras.layers.Dense</code> layer, then, <code>filter_indices = [22]</code>, <code>layer = dense_layer</code>.</p>
<p>One could also set filter indices to more than one value. For example, <code>filter_indices = [22, 23]</code> should
(hopefully) show attention map that corresponds to both 22, 23 output categories.</p>
<p><em>Notes:</em></p>
<p>This technique deprecates occlusion maps as it gives similar results, but with one-pass gradient computation
as opposed inefficient sliding window approach.</p>
<p><em>Returns:</em></p>
<p>The heatmap image indicating the input regions whose change would most contribute towards
maximizing the output of <code>filter_indices</code>.</p>
<hr />
<h3 id="visualize_regression_cam"><a href="https://github.com/raghakot/keras-vis/tree/master/vis/visualization.py#L440">visualize_regression_cam</a></h3>
<pre><code class="python">visualize_regression_cam(model, layer_idx, output_indices, targets, seed_input, \
    penultimate_layer_idx=None)
</code></pre>

<p>Generates gradient based class activation map (grad-CAM) over the <code>seed_input</code> for driving the outputs of
<code>output_indices</code> in the given <code>layer_idx</code> to the corresponding regression <code>targets</code>.</p>
<p><em>Args:</em></p>
<ul>
<li><strong>model</strong>:  The <code>keras.models.Model</code> instance. The model input shape must be: <code>(samples, channels, image_dims...)</code>
  if <code>image_data_format=channels_first</code> or <code>(samples, image_dims..., channels)</code> if
  <code>image_data_format=channels_last</code>.</li>
<li><strong>layer_idx</strong>:  The layer index within <code>model.layers</code> whose filters needs to be visualized.</li>
<li><strong>output_indices</strong>:  Output indices within the layer for the corresponding regression <code>targets</code>.</li>
<li><strong>targets</strong>:  The regression targets for the corresponding <code>output_indices</code>.</li>
<li><strong>seed_input</strong>:  The input image for which activation map needs to be visualized.</li>
<li><strong>penultimate_layer_idx</strong>:  The pre-layer to <code>layer_idx</code> whose feature maps should be used to compute gradients
  wrt filter output. If not provided, it is set to the nearest penultimate <code>Conv</code> or <code>Pooling</code> layer.</li>
</ul>
<p><em>Example:</em></p>
<p>Consider a model with continuous regression output such as the self driving car.</p>
<p>If you wanted to visualize the attention over input image that would cause the final <code>Dense</code> layer output_index
0 to output 45 degrees, then you would set <code>output_indices = 0</code>, <code>layer_idx = dense_layer_idx</code> and <code>targets = 45</code>.</p>
<p>Suppose this model has two regression outputs, one for the steering angle and another for acceleration.
Setting <code>output_indices = [0, 1]</code>, <code>layer_idx = dense_layer_idx</code> and <code>targets = [45, -5]</code> would generate
the attention heatmap over input that would cause the steering angle to increase and acceleration to decrease.</p>
<p><em>Returns:</em></p>
<p>The heatmap image indicating the <code>seed_input</code> regions whose change would most contribute towards <code>output_indices</code>
outputs to approach their corresponding <code>targets</code>.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../vis.utils.utils/" class="btn btn-neutral float-right" title="utils">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../vis.optimizer/" class="btn btn-neutral" title="optimizer"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="http://github.com/raghakot/keras-vis" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../vis.optimizer/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../vis.utils.utils/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

</body>
</html>
